summary(train1[, 1:5])
model1 <- train(classe ~ yaw_belt + gyros_belt_x, data = train1, method = "glm", preProcess = c("BoxCox"))
library(caret)
preproc1 <- preProcess(train1[, -53], method = c("center", "scale"))
preproc1
trainPC <- predict(preproc1, train1[, -53])
hist(trainPC$roll_belt)
preproc1 <- preProcess(train1[, -53], method = c("center", "scale", "nzv"))
trainPC <- predict(preproc1, train1[, -53])
hist(trainPC$roll_belt)
preproc1
str(train1)
train2 <- as.numeric(train1)
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
#for irrelevant variables
processing <- c(processing, 1:7)
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
training <- training[, -processing]
testing <- testing[, - processing]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
preproc1 <- preProcess(train1[,-53], method = c("scale", "center", "nzv"))
ppreproc1
preproc1
preproc1 <- preProcess(train1[,-53], method = c("BoxCox", "nzv"))
preproc1
trainPC <- predict(preproc1, train1[,-53])
hist(trainPC$roll_belt)
library(Hmisc)
v1 <- cut2(train1$roll_belt, g = 2)
table(v1)
v1 <- cut2(train1$roll_belt, g = 3)
table(v1)
View(train1)
hist(train1$pitch_belt)
#v1
train1$roll_belt <- cut2(train1$roll_belt, g = 3)
v2 <- cut2(train1$pitch_belt, g = 3)
table(v2)
hist(v2)
v2 <- cut2(train1$pitch_belt, g = 2)
table(v2)
library(car)
scatterplot(train1$roll_belt, train1$classe)
scatterplot(train1$roll_belt, col = train1$classe)
scatterplot(train1$roll_belt, train1$pitch_belt col = train1$classe)
scatterplot(train1$roll_belt, train1$pitch_belt, col = train1$classe)
boxplot(train1$roll_belt)
boxplot(train1$pitch_belt)
summary(train[,3])
summary(train1[,3])
boxplot(train1[,3])
boxplot(train1[,2])
hist(train1[,2])
hist(train1[,2], breaks = 50)
hist(train1[,2], breaks = 100)
nonzerovar <- nearZeroVar(train1)
nonzerovar <- nearZeroVar(train1)
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
#for irrelevant variables
processing <- c(processing, 1:7)
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
training <- training[, -processing]
testing <- testing[, - processing]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
model1 <- train(classe ~ ., data = train1, method = "rpart")
library(rpart)
fancyRpartPlot(model1$finalModel)
model1 <- rpart(classe ~ ., data = train1)
library(rpart)
fancyRpartPlot(model1$finalModel)
library(rattle)
fancyRpartPlot(model1$finalModel)
fancyRpartPlot(model1)
controltrain <- trainControl(method="cv", number=10)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
fancyRpartPlot(model1)
fancyRpartPlot(model1$finalModel)
controltrain <- trainControl(method="cv", number=5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
fancyRpartPlot(model1$finalModel)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
fancyRpartPlot(model1$finalModel)
model1 <- train(classe ~ ., data = train1, method = "rpart")
fancyRpartPlot(model1$finalModel)
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
#for irrelevant variables
processing <- c(processing, 1:7)
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
training <- training[, -processing]
testing <- testing[, - processing]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
controltrain <- trainControl(method = "cv", number = 10)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
fancyRpartPlot(model1$finalModel)
controltrain <- trainControl(method = "cv", number = 2)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
fancyRpartPlot(model1$finalModel)
fancyRpartPlot(model1$finalModel)
model1 <- rpart(classe ~ ., data = train1)
fancyRpartPlot(model1)
rpart.plot::model1
rpart.plot(model1)
library(rpart)
rpart.plot(model1)
library(rpart)
library(rpart.plot)
rpart.plot(model1)
predict1 <- predict(model1, test1[,-53])
sum(predict1 == test1$classe)
predict1 <- predict(model1, test1[,-53], type = "class")
confusionMatrix(predict1, test1$classe)
controltrain <- trainControl(method = "cv", number = 10)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
fancyRpartPlot(model1)
fancyRpartPlot(model1$finalModel)
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53], type = "class")
accuracy1 <- confusionMatrix(predict1, test1$classe)
accuracy1
controltrain <- trainControl(method = "cv", number = 10)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53], type = "class")
accuracy1 <- confusionMatrix(predict1, test1$classe)
accuracy1
controltrain <- trainControl(method = "cv", number = 10)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain)
predict2 <- predict(model2, test1[,-53], type = "class")
accuracy2 <- confusionMatrix(predict1, test1$classe)
controltrain <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain)
predict2 <- predict(model2, test1[,-53], type = "class")
accuracy2 <- confusionMatrix(predict1, test1$classe)
controltrain <- trainControl(method = "cv", number = 10)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain)
rm(list = ls())
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
processing <- c(processing, 1:7)
training <- training[, -processing]
testing <- testing[, - processing]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53], type = "class")
predict1 <- predict(model1, test1[,-53])
confusionMatrix(predict1, test1$classe)
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain)
model2 <- train(classe ~ ., data = train1, method = "rf")
model2 <- train(classe ~ ., data = train1, method = "rf", ntree = 4)
predict2 <- predict(model2, test1[,-53], type = "class")
predict2 <- predict(model2, test1[,-53])
confusionMatrix(predict2, test1$classe)
controltrain <- trainControl(method = "cv", number = 5)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, ntree = 4)
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 4)
predict2 <- predict(model2, test1[,-53], type = "class")
predict2 <- predict(model2, test1[,-53])
confusionMatrix(predict2, test1$classe)
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 8)
predict2 <- predict(model2, test1[,-53])
confusionMatrix(predict2, test1$classe)
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 16)
predict2 <- predict(model2, test1[,-53])
confusionMatrix(predict2, test1$classe)
predicttrain <- predict(model2, train1[,-53])
confusionMatrix(predicttrain, train1$classe)
controltrain <- trainControl(method = "cv", number = 5)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain)
model3 <- train(classe ~ ., data = train1, method = "gbm")
model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = FALSE)
model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = FALSE, ntrees = 4)
model3 <- train(classe ~ ., data = train1, method = "gbm", n.trees = 4)
model3 <- train(classe ~ ., data = train1, method = "gbm", n.tree = 4, verbose = TRUE)
model3 <- train(classe ~ ., data = train1, method = "gbm", n.trees = 4, verbose = TRUE)
warnings()
model3 <- gbm(classe ~., data = train1, n.trees = 10)
library(gbm)
model3 <- gbm(classe ~., data = train1, n.trees = 10)
predict3 <- predict(model3, test1[,-53])
model3 <- train(classe ~ ., data = train1, method = "gbm", n.trees = 4, verbose = TRUE)
controltrain <- trainControl(method = "repeatedcv", number = 5)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = FALSE)
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = FALSE)
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE)
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE, n.trees = 10)
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE, ntrees = 10)
model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = TRUE)
predict3 <- predict(model3, test1[,-53])
confusionMatrix(predict3, test1$classe)
summary(training[, 12])
summary(training[, 13])
save.image("~/Documents/R/projectPMLdata.RData")
trainingdata <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
x <- ((is.na(trainingdata)) | (trainingdata==""))
y <- apply(x, 2, sum)
y <- y/15699
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
traindata1 <- train1[, -colindex]
x<- (trainingdata == "")
str(x)
y1 <- apply(x, 2, sum)
> y1 <- y1/19622
> colindex1 <- (y > 0.5)
y1 <- apply(x, 2, sum)
> y1 <- y1/19622
> colindex1 <- (y1 > 0.5)
y1 <- apply(x, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(train1)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
colindex <- c(colindex, colindex1)
traindata <- trainingdata[, -colindex]
y1 <- apply(x, 2, sum)
> y1 <- y1/19622
> colindex1 <- (y1 > 0.5)
> colindex1 <- which(colindex1 == TRUE)
> x <- is.na(train1)
> y <- apply(x, 2, sum)
> y <- y/19622
> colindex <- (y > 0.5)
> colindex <- which(colindex == TRUE)
y1 <- apply(x, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(train1)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
colindex <- intersect(colindex, colindex1)
traindata <- trainingdata[, -colindex]
x <- (trainingdata == "")
y1 <- apply(x, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(train1)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
col1 <- intersect(colindex, colindex1)
traindata1 <- trainingdata[, -col1]
x <- (trainingdata == "")
y1 <- apply(x, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(trainingdata)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
col1 <- intersect(colindex, colindex1)
traindata1 <- trainingdata[, -col1]
View(trainingdata)
x1 <- (trainingdata == "")
y1 <- apply(x1, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(trainingdata)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
col1 <- union(colindex, colindex1)
x1 <- (trainingdata == "") | (is.na(trainingdata))
y1 <- apply(x1, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x1 <- (trainingdata == "")
y1 <- apply(x1, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
colindex1
summary(trainingdata[, 12])
summary(trainingdata[, 12])
summary(trainingdata[, 12:13])
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
processing <- c(processing, 1:7)
training <- training[, -processing]
testing <- testing[, - processing]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
#using trees
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53])
accuracy1 <- confusionMatrix(predict1, test1$classe)
#random forests
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 16)
predicttrain <- predict(model2, train1[,-53])
predict2 <- predict(model2, test1[,-53])
accuracy2 <- confusionMatrix(predict2, test1$classe)
#gradient boosting
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
#worked
#model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = TRUE)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE)
predict3 <- predict(model3, test1[,-53])
accuracy3 <- confusionMatrix(predict3, test1$classe)
accuracy1
accuracy2
accuracy3
accuracy3[[1]]
accuracy3[[2]]
accuracy3[[3]]
accuracy3[[3]][1]
accuracy1[[3]][1]
accuracy2[[3]][1]
final_predict <- predict(testing, model2)
final_predict <- predict(testing[, -53], model2)
final_predict <- predict(model2, testing[, -53])
final_predict
rpart.plot(model1)
rpart.plot(model1$finalModel)
accuracy[[2]]
accuracy1[[2]]
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
summary(train1[, 12:15])
x1 <- (train1 == "")
y1 <- apply(x1, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(train1)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
col1 <- union(colindex, colindex1)
train1 <- train1[, -col1]
test1 <- test1[, -col1]
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
processing <- c(processing, 1:7)
training <- training[, -processing]
testing <- testing[, - processing]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
#using trees
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53])
accuracy1 <- confusionMatrix(predict1, test1$classe)
#random forests
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 16)
predicttrain <- predict(model2, train1[,-53])
predict2 <- predict(model2, test1[,-53])
accuracy2 <- confusionMatrix(predict2, test1$classe)
#gradient boosting
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
#worked
#model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = TRUE)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE)
predict3 <- predict(model3, test1[,-53])
accuracy3 <- confusionMatrix(predict3, test1$classe)
accuracy1
accuracy2
accuracy3
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
#processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
#processing <- c(processing, 1:7)
x1 <- (training == "")
y1 <- apply(x1, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(training)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
col1 <- union(colindex, colindex1)
training <- training[, -col1]
testing <- testing[, - col1]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
#using trees
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53])
accuracy1 <- confusionMatrix(predict1, test1$classe)
#random forests
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 16)
predicttrain <- predict(model2, train1[,-53])
predict2 <- predict(model2, test1[,-53])
accuracy2 <- confusionMatrix(predict2, test1$classe)
#gradient boosting
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
#worked
#model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = TRUE)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE)
predict3 <- predict(model3, test1[,-53])
accuracy3 <- confusionMatrix(predict3, test1$classe)
c(1:7)
rm(list = ls())
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
#processing <- c(12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150)
#processing <- c(processing, 1:7)
x1 <- (training == "")
y1 <- apply(x1, 2, sum)
y1 <- y1/19622
colindex1 <- (y1 > 0.5)
colindex1 <- which(colindex1 == TRUE)
x <- is.na(training)
y <- apply(x, 2, sum)
y <- y/19622
colindex <- (y > 0.5)
colindex <- which(colindex == TRUE)
col1 <- union(colindex, colindex1)
training <- training[, -col1]
testing <- testing[, - col1]
training <- training[, -c(1:7)]
testing <- testing[, -c(1:7)]
set.seed(1313)
library(caret)
trainIndex <-  createDataPartition(training$classe, p = 0.8, list = FALSE)
train1 <- training[trainIndex, ]
test1 <- training[-trainIndex, ]
#using trees
controltrain <- trainControl(method = "cv", number = 5)
model1 <- train(classe ~ ., data = train1, method = "rpart", trControl = controltrain)
predict1 <- predict(model1, test1[,-53])
accuracy1 <- confusionMatrix(predict1, test1$classe)
#random forests
controltrain <- trainControl(method = "cv", number = 5)
model2 <- train(classe ~ ., data = train1, method = "rf", trControl = controltrain, ntree = 16)
predicttrain <- predict(model2, train1[,-53])
predict2 <- predict(model2, test1[,-53])
accuracy2 <- confusionMatrix(predict2, test1$classe)
#gradient boosting
controltrain <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
#worked
#model3 <- train(classe ~ ., data = train1, method = "gbm", verbose = TRUE)
model3 <- train(classe ~ ., data = train1, method = "gbm", trControl = controltrain, verbose = TRUE)
predict3 <- predict(model3, test1[,-53])
accuracy3 <- confusionMatrix(predict3, test1$classe)
accuracy1
setwd("~/Documents/R")
setwd("~/Documents/R/ProjectPML")
